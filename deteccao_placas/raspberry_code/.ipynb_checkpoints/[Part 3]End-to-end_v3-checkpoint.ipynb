{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['brazilian_car_plate.jpg',\n",
       " 'china_car_plate.jpg',\n",
       " 'china_motor_plate.jpg',\n",
       " 'germany_car_plate.jpg',\n",
       " 'image1.jpg',\n",
       " 'image10.jpg',\n",
       " 'image11.jpg',\n",
       " 'image12.jpg',\n",
       " 'image13.jpg',\n",
       " 'image14.jpg',\n",
       " 'image15.jpg',\n",
       " 'image16.jpg',\n",
       " 'image17.jpg',\n",
       " 'image18.jpg',\n",
       " 'image19.jpg',\n",
       " 'image2.jpg',\n",
       " 'image20.jpg',\n",
       " 'image21.jpg',\n",
       " 'image22.jpg',\n",
       " 'image23.jpg',\n",
       " 'image24.jpg',\n",
       " 'image25.jpg',\n",
       " 'image3.jpg',\n",
       " 'image4.jpg',\n",
       " 'image5.jpg',\n",
       " 'image6.jpg',\n",
       " 'image7.jpg',\n",
       " 'image8.jpg',\n",
       " 'india_car_plate.jpg',\n",
       " 'india_motor_plate.jpg',\n",
       " 'inventario.png',\n",
       " 'japan_car_plate.JPG',\n",
       " 'japan_motor_plate.JPG',\n",
       " 'koera_car_plate.jpg',\n",
       " 'koera_motor_plate.jpg',\n",
       " 'multiple_plates.png',\n",
       " 'papelao.jpg',\n",
       " 'parabens.png',\n",
       " 'russia_car_plate.jpg',\n",
       " 'russia_motor_plate.jpg',\n",
       " 'saudi_car_plate.jpg',\n",
       " 'thailand_car_plate.jpg',\n",
       " 'thailand_motor_plate.jpg',\n",
       " 'turkey_car_plate.jpg',\n",
       " 'usa_car_plate.jpg',\n",
       " 'usa_motor_plate.jpg',\n",
       " 'vietnam_car_rectangle_plate.jpg',\n",
       " 'vietnam_car_square_plate.jpg',\n",
       " 'vietnam_motor_plate.jpg']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "onlyfiles = [f for f in listdir('./Plate_examples')]\n",
    "onlyfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove warning message\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# required library\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from local_utils import detect_lp\n",
    "from os.path import splitext,basename\n",
    "from keras.models import model_from_json\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.applications.mobilenet_v2 import preprocess_input\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import glob\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path):\n",
    "    try:\n",
    "        path = splitext(path)[0]\n",
    "        with open('%s.json' % path, 'r') as json_file:\n",
    "            model_json = json_file.read()\n",
    "        model = model_from_json(model_json, custom_objects={})\n",
    "        model.load_weights('%s.h5' % path)\n",
    "        print(\"Loading model successfully...\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpod_net_path = \"wpod-net.json\"\n",
    "wpod_net = load_model(wpod_net_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wpod_net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-db5d1d2087e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mtest_image_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Plate_examples/image22.jpg\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mvehicle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLpImg\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mcor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_plate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_image_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-db5d1d2087e4>\u001b[0m in \u001b[0;36mget_plate\u001b[1;34m(image_path, Dmax, Dmin)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mside\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mratio\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mDmin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mbound_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mside\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0m_\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mLpImg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetect_lp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwpod_net\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvehicle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbound_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlp_threshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mvehicle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLpImg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'wpod_net' is not defined"
     ]
    }
   ],
   "source": [
    "def preprocess_image(image_path,resize=False):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img / 255\n",
    "    if resize:\n",
    "        img = cv2.resize(img, (224,224))\n",
    "    return img\n",
    "\n",
    "def get_plate(image_path, Dmax=608, Dmin = 608):\n",
    "    vehicle = preprocess_image(image_path)\n",
    "    ratio = float(max(vehicle.shape[:2])) / min(vehicle.shape[:2])\n",
    "    side = int(ratio * Dmin)\n",
    "    bound_dim = min(side, Dmax)\n",
    "    _ , LpImg, _, cor = detect_lp(wpod_net, vehicle, bound_dim, lp_threshold=0.5)\n",
    "    return vehicle, LpImg, cor\n",
    "\n",
    "test_image_path = \"Plate_examples/image22.jpg\"\n",
    "vehicle, LpImg ,cor = get_plate(test_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (len(LpImg)): #check if there is at least one license image\n",
    "    # Scales, calculates absolute values, and converts the result to 8-bit.\n",
    "    plate_image = cv2.convertScaleAbs(LpImg[0], alpha=(255.0))\n",
    "    \n",
    "    # convert to grayscale and blur the image\n",
    "    gray = cv2.cvtColor(plate_image, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray,(7,7),0)\n",
    "    \n",
    "    # Applied inversed thresh_binary \n",
    "    binary = cv2.threshold(blur, 180, 255,cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "    \n",
    "    kernel3 = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    thre_mor = cv2.morphologyEx(binary, cv2.MORPH_DILATE, kernel3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sort_contours() function to grab the contour of each digit from left to right\n",
    "def sort_contours(cnts,reverse = False):\n",
    "    i = 0\n",
    "    boundingBoxes = [cv2.boundingRect(c) for c in cnts]\n",
    "    (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes), key=lambda b: b[1][i], reverse=reverse))\n",
    "    return cnts\n",
    "\n",
    "cont, _  = cv2.findContours(binary, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Initialize a list which will be used to append charater image\n",
    "crop_characters = []\n",
    "\n",
    "# define standard width and height of character\n",
    "digit_w, digit_h = 30, 60\n",
    "for c in sort_contours(cont):\n",
    "    (x, y, w, h) = cv2.boundingRect(c)\n",
    "    ratio = h/w\n",
    "    if 0.35 < (w/h) < 1.2: # se a divisão da largura pela altura está no intervalo (0.35, 1.2)\n",
    "        if 0.03 < ((w*h)/(plate_image.shape[0] * plate_image.shape[1])) < 0.1: # se a área do identificado/area da imagem está entre (0.03, 0.1)\n",
    "            # Sperate number and gibe prediction\n",
    "            curr_num = thre_mor[y:y+h,x:x+w]\n",
    "            curr_num = cv2.resize(curr_num, dsize=(digit_w, digit_h))\n",
    "            _, curr_num = cv2.threshold(curr_num, 220, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "            crop_characters.append(curr_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model architecture, weight and labels\n",
    "json_file = open('MobileNets_character_recognition.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "model.load_weights(\"License_character_recognition_weight.h5\")\n",
    "print(\"[INFO] Model loaded successfully...\")\n",
    "\n",
    "labels = LabelEncoder()\n",
    "labels.classes_ = np.load('license_character_classes.npy')\n",
    "print(\"[INFO] Labels loaded successfully...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-processing input images and pedict with model\n",
    "def predict_from_model(image,model,labels):\n",
    "    image = cv2.resize(image,(80,80))\n",
    "    image = np.stack((image,)*3, axis=-1)\n",
    "    prediction = labels.inverse_transform([np.argmax(model.predict(image[np.newaxis,:]))])\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_string = ''\n",
    "for i,character in enumerate(crop_characters):\n",
    "    title = np.array2string(predict_from_model(character,model,labels))\n",
    "    final_string+=title.strip(\"'[]\")\n",
    "\n",
    "print(final_string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
